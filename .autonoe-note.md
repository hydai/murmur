# Autonoe Planning Notes — Localtype

## Project Summary
Localtype is a privacy-first BYOK (Bring Your Own Key) voice typing app built with Tauri 2 (Rust backend + Svelte 5 frontend). It captures audio, sends it to user-chosen STT providers (ElevenLabs/OpenAI/Groq), post-processes via local CLI tools (gemini-cli/copilot-cli), and outputs to clipboard/keyboard.

## Planning Decisions

### Task Structure (14 tasks across 5 phases)
- **Phase 1 (Foundation)**: Tasks 1-3 — workspace scaffold, audio capture, ElevenLabs STT
- **Phase 2 (Pipeline)**: Tasks 4-5 — LLM post-processing, full pipeline with clipboard output
- **Phase 3 (Multi-provider + Commands)**: Tasks 6-7 — additional STT providers, voice commands
- **Phase 4 (Features + Polish)**: Tasks 8-12 — translation, dictionary, settings, UI polish, system tray
- **Phase 5 (Hardening + Distribution)**: Tasks 13-14 — permissions/testing/errors, .dmg bundle

### Dependency Graph
```
FOUND-001 (#1) ──┬──→ AUDIO-001 (#2) → STT-001 (#3) ──┬──→ OUT-001 (#5) ──┬──→ CMD-001 (#7) ──┬──→ TRANS-001 (#8) ──┐
                 │                                      │                   ├──→ DICT-001 (#9) ──┤                    │
                 └──→ LLM-001 (#4) ────────────────────┘                   └──→ UI-001 (#11) ───┤                    │
                                                                                                 │                    │
                      STT-001 (#3) → STT-002 (#6) → SET-001 (#10) → SYS-001 (#12) ─────────────┤                    │
                                                                                                 │                    │
                                                                       HARD-001 (#13) ←─────────┘────────────────────┘
                                                                            │
                                                                       DIST-001 (#14) ← UI-001 (#11) + SYS-001 (#12) + HARD-001 (#13)
```

### Parallelism Opportunities
- After Task #1: Tasks #2 and #4 can run in parallel (audio capture vs LLM processing)
- After Task #5: Tasks #7, #9, and #11 can run in parallel (voice commands vs dictionary vs UI polish)
- After Task #3: Tasks #5 and #6 can run in parallel (pipeline vs additional providers)

### Key Technical Notes
- ElevenLabs uses WebSocket streaming; OpenAI/Groq use REST batch with audio chunking
- LLM processing goes through local CLI tools, NOT direct API calls
- Audio pipeline: cpal → bounded channels → resample 16kHz mono → VAD → STT provider
- macOS-specific: needs `macos-private-api` feature flag for transparent overlay
- No worktree guidance found — tasks will execute sequentially

### Current State
- Brand new project, no existing code
- Only SPEC.md exists in the repository
- No git history initialized yet
