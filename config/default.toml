# Murmur Default Configuration

# STT Provider Selection
# Options: "elevenlabs", "openai", "groq", "apple_stt", "custom_stt"
# "apple_stt" uses on-device Apple SpeechTranscriber (macOS 26+, no API key needed)
# "custom_stt" connects to any OpenAI-compatible Whisper endpoint (see [http_stt_config])
stt_provider = "elevenlabs"

# LLM Processor Selection
# CLI providers: "gemini", "copilot"
# HTTP API providers: "openai_api", "claude_api", "gemini_api", "custom_api"
# Local: "apple_llm"
llm_processor = "gemini"

# LLM Model Override (optional)
# Leave commented to use provider defaults:
#   gemini CLI → "gemini-3-flash-preview", copilot CLI → "gpt-5-mini"
#   openai_api → "gpt-4o-mini", claude_api → "claude-sonnet-4-20250514"
#   gemini_api → "gemini-2.0-flash"
# llm_model = "gemini-3-flash-preview"

# Output Mode
# Options: "clipboard", "keyboard", "both"
output_mode = "clipboard"

# Global Hotkey
# Format: "Modifier+Key" (e.g., "Cmd+Shift+L", "Ctrl+Alt+T")
hotkey = "Ctrl+`"

# API Keys
# Store your API keys here or use environment variables
[api_keys]
# elevenlabs = "your-elevenlabs-api-key"
# openai = "your-openai-api-key"       # shared between STT (Whisper) and LLM (Chat Completions)
# groq = "your-groq-api-key"
# anthropic = "your-anthropic-api-key"  # for Claude API
# google_ai = "your-google-ai-key"     # for Gemini API (distinct from Gemini CLI)
# custom_llm = "your-custom-api-key"   # for custom OpenAI-compatible endpoints

# Apple STT Locale
# "auto" = detect system language, or set a specific locale (e.g. "en_US", "ja_JP", "zh_TW")
apple_stt_locale = "auto"

# ElevenLabs STT Language
# "auto" = automatic language detection, or set an ISO 639-3 code (e.g. "eng", "jpn", "zho")
elevenlabs_language = "auto"

# HTTP LLM Provider Configuration (for custom_api)
# [http_llm_config]
# custom_base_url = "http://localhost:11434/v1"  # e.g., Ollama, LM Studio
# custom_display_name = "Local Ollama"

# HTTP STT Provider Configuration (for custom_stt)
# Connect to any OpenAI-compatible Whisper endpoint (whisper.cpp, faster-whisper, LocalAI, etc.)
# [http_stt_config]
# custom_base_url = "http://localhost:8080/v1"   # POST {base_url}/audio/transcriptions
# custom_display_name = "Local Whisper"
# custom_model = "whisper-1"                     # model name sent in multipart form
# language = "en"                                # ISO-639-1 language hint (optional)

# UI Preferences
[ui_preferences]
# Window opacity (0.0 - 1.0)
opacity = 0.9

# Show waveform indicator during recording
show_waveform = true

# Theme: "light" or "dark"
theme = "dark"
